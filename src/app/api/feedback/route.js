// route.js code
import { NextResponse } from "next/server";
import OpenAI from "openai";
import { createCanvas, loadImage } from "canvas";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function POST(req) {
  try {
    const formData = await req.formData();
    const taskDescription = formData.get("taskDescription");
    const imageFile = formData.get("image");
    const feedbackType = formData.get("feedbackType") || "sketch-text";

    let buffer;
    if (imageFile) {
      const arrayBuffer = await imageFile.arrayBuffer();
      buffer = Buffer.from(arrayBuffer);
    }

    let feedback;

    switch (feedbackType) {
      case "sketch-text":
        if (!imageFile) {
          return NextResponse.json(
            { error: "Missing image file for sketch-text feedback." },
            { status: 400 }
          );
        }
        const sketchTextResponse = await openai.chat.completions.create({
          model: "gpt-4o",
          max_tokens: 400,
          messages: [
            {
              role: "system",
              content: `ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è¨­è¨ˆå°å¸«ï¼Œè«‹åˆ†æä½¿ç”¨è€…çš„æ‰‹ç¹ªè‰åœ–ï¼Œä¸¦çµ¦å‡ºèˆ‡é•·ç…§ä¸­å¿ƒæœ‰é—œçš„è¨­è¨ˆæ”¹é€²å»ºè­°ï¼ŒåŒ…æ‹¬ææ–™ã€é€ å‹ã€æ©Ÿæ§‹ç­‰æ–¹é¢çš„å‰µæ–°æ–¹å‘ã€‚`,
            },
            {
              role: "user",
              content: [
                {
                  type: "text",
                  text: `è¨­è¨ˆä»»å‹™ï¼š${taskDescription}ï¼Œè«‹æ ¹æ“šæˆ‘çš„è‰åœ–çµ¦å‡ºå…·é«”çš„åˆ†æå’Œå»ºè­°ï¼Œä¸¦ä»¥ç´”æ–‡å­—å›è¦†ã€‚`,
                },
                {
                  type: "image_url",
                  image_url: {
                    url: `data:${imageFile.type};base64,${buffer.toString(
                      "base64"
                    )}`,
                  },
                },
              ],
            },
          ],
        });
        const fullTextResponse =
          sketchTextResponse.choices?.[0]?.message?.content || "";
        // ğŸš¨ ä¿®æ­£ï¼šç›´æ¥å°‡å®Œæ•´å›è¦†ä½œç‚ºå»ºè­°å…§å®¹
        feedback = {
          type: "text",
          suggestions: fullTextResponse,
          analysis: "",
        };
        break;

      case "sketch-image":
        if (!imageFile) {
          return NextResponse.json(
            { error: "Missing image file for sketch-image feedback." },
            { status: 400 }
          );
        }
        try {
          const analysisResponse = await openai.chat.completions.create({
            model: "gpt-4o",
            max_tokens: 200,
            messages: [
              {
                role: "system",
                content: `ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è¨­è¨ˆå°å¸«ï¼Œè«‹åˆ†æä½¿ç”¨è€…æä¾›çš„è‰åœ–ï¼Œä¸¦æ ¹æ“šå…¶é¢¨æ ¼å’Œå…§å®¹ï¼Œæä¾›å…·é«”çš„æ”¹é€²å»ºè­°æè¿°ã€‚é€™äº›å»ºè­°å°‡ç›´æ¥ç”¨æ–¼åœ–åƒç”Ÿæˆï¼Œè«‹å°ˆæ³¨æ–¼å¦‚ä½•è®“è¨­è¨ˆåœ¨é•·ç…§ä¸­å¿ƒç’°å¢ƒä¸‹æ›´å¯¦ç”¨ã€ç¾è§€ï¼Œä¸”ç¬¦åˆäººé«”å·¥å­¸ã€‚**è«‹ç”¨è‹±æ–‡å›è¦†ï¼Œä¸è¦ä½¿ç”¨ä¸­æ–‡ã€‚**`,
              },
              {
                role: "user",
                content: [
                  {
                    type: "text",
                    text: `è«‹åˆ†ææˆ‘çš„è‰åœ–ï¼Œä¸¦æè¿°å…·é«”çš„æ”¹é€²å»ºè­°ã€‚é€™äº›å»ºè­°å°‡ç”¨æ–¼ç”Ÿæˆä¸€å€‹æ”¹é€²ç‰ˆæœ¬çš„åœ–åƒã€‚**è«‹ç”¨è‹±æ–‡å›è¦†ï¼Œä¸è¦ä½¿ç”¨ä¸­æ–‡ã€‚**`,
                  },
                  {
                    type: "image_url",
                    image_url: {
                      url: `data:${imageFile.type};base64,${buffer.toString(
                        "base64"
                      )}`,
                    },
                  },
                ],
              },
            ],
          });
          const analysisText =
            analysisResponse.choices?.[0]?.message?.content || "";
          const imageBuffer = buffer;
          const originalImage = await loadImage(imageBuffer);
          const imageWidth = originalImage.width;
          const imageHeight = originalImage.height;
          const totalPixels = imageWidth * imageHeight;
          const MIN_PIXELS = 262144;
          let finalBuffer = imageBuffer;
          if (totalPixels < MIN_PIXELS) {
            const newWidth = 1024;
            const newHeight = 1024;
            const canvas = createCanvas(newWidth, newHeight);
            const ctx = canvas.getContext("2d");
            ctx.drawImage(originalImage, 0, 0, newWidth, newHeight);
            finalBuffer = canvas.toBuffer("image/png");
          }
          const apiHost = "https://api.stability.ai";
          const formData = new FormData();
          formData.append("init_image", new Blob([finalBuffer]), "sketch.png");
          formData.append("steps", "50");
          formData.append("cfg_scale", "7.5");
          formData.append("clip_guidance_preset", "FAST_BLUE");
          formData.append("sampler", "K_DPMPP_2M");
          formData.append("samples", "1");
          formData.append("text_prompts[0][text]", `${analysisText}`);
          formData.append("text_prompts[0][weight]", "0.5");
          formData.append(
            "text_prompts[1][text]",
            "low quality, bad anatomy, ugly, deformed, blurry, grainy, bad composition, watermark, text, signature, cartoon, illustration, amateur, messy background, grey background, dirty background, crowded, busy, distracting elements"
          );
          formData.append("text_prompts[1][weight]", "-1");
          const imageResponse = await fetch(
            `${apiHost}/v1/generation/stable-diffusion-xl-1024-v1-0/image-to-image`,
            {
              method: "POST",
              headers: {
                Authorization: `Bearer ${process.env.STABILITY_AI_API_KEY}`,
                Accept: "application/json",
              },
              body: formData,
            }
          );
          if (!imageResponse.ok) {
            const errorData = await imageResponse.json();
            throw new Error(JSON.stringify(errorData));
          }
          const imageData = await imageResponse.json();
          const suggestions = `data:image/png;base64,${imageData.artifacts[0].base64}`;
          feedback = {
            type: "image",
            suggestions: suggestions,
            analysis: analysisText,
          };
        } catch (error) {
          console.error("åœ–åƒç”ŸæˆéŒ¯èª¤:", error);
          feedback = {
            type: "text",
            suggestions: "åœ–åƒç”Ÿæˆæš«æ™‚ä¸å¯ç”¨ï¼Œè«‹åƒè€ƒä¸Šæ–¹çš„æ–‡å­—åˆ†æå»ºè­°ã€‚",
            analysis: "",
          };
        }
        break;

      case "task-text":
        const taskTextResponse = await openai.chat.completions.create({
          model: "gpt-4o",
          max_tokens: 400,
          messages: [
            {
              role: "system",
              content: `ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è¨­è¨ˆå°å¸«ï¼Œè«‹æ ¹æ“šè¨­è¨ˆä»»å‹™æä¾›å‰µæ„ç™¼æƒ³å»ºè­°ã€‚`,
            },
            {
              role: "user",
              content: `è¨­è¨ˆä»»å‹™ï¼š${taskDescription}ï¼Œè«‹é‡å°é€™å€‹è¨­è¨ˆä»»å‹™æä¾›å‰µæ„ç™¼æƒ³å’Œè¨­è¨ˆå»ºè­°ï¼Œä¸¦ä»¥ç´”æ–‡å­—å›è¦†ã€‚`,
            },
          ],
        });
        const fullTaskTextResponse =
          taskTextResponse.choices?.[0]?.message?.content || "";
        // ğŸš¨ ä¿®æ­£ï¼šç›´æ¥å°‡å®Œæ•´å›è¦†ä½œç‚ºå»ºè­°å…§å®¹
        feedback = {
          type: "text",
          suggestions: fullTaskTextResponse,
          analysis: "",
        };
        break;

      case "task-image":
        const taskImageResponse = await openai.chat.completions.create({
          model: "gpt-4o",
          max_tokens: 300,
          messages: [
            {
              role: "system",
              content: `ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è¨­è¨ˆå°å¸«ï¼Œè«‹åŸºæ–¼è¨­è¨ˆä»»å‹™å‰µé€ è¦–è¦ºåŒ–çš„è¨­è¨ˆå»ºè­°ã€‚è«‹è©³ç´°æè¿°ç¬¦åˆä»»å‹™éœ€æ±‚çš„è¨­è¨ˆæ¦‚å¿µï¼Œç”¨æ–¼ç”Ÿæˆåƒè€ƒåœ–åƒã€‚**è«‹ç”¨è‹±æ–‡å›è¦†ï¼Œä¸è¦ä½¿ç”¨ä¸­æ–‡ã€‚**`,
            },
            {
              role: "user",
              content: `è¨­è¨ˆä»»å‹™ï¼š${taskDescription}ã€‚è«‹é‡å°é€™å€‹è¨­è¨ˆä»»å‹™ï¼Œè©³ç´°æè¿°ä¸€å€‹å„ªç§€çš„è¨­è¨ˆè§£æ±ºæ–¹æ¡ˆï¼ŒåŒ…æ‹¬å…·é«”çš„è¦–è¦ºç‰¹å¾µã€åŠŸèƒ½å…ƒç´ ã€ææ–™è³ªæ„Ÿç­‰ï¼Œç”¨æ–¼ç”Ÿæˆåƒè€ƒåœ–åƒã€‚**è«‹ç”¨è‹±æ–‡å›è¦†ï¼Œä¸è¦ä½¿ç”¨ä¸­æ–‡ã€‚**`,
            },
          ],
        });
        const taskImageDescription =
          taskImageResponse.choices?.[0]?.message?.content || "";
        const dallEResponse = await openai.images.generate({
          model: "dall-e-3",
          prompt: `Design concept for: ${taskDescription}. ${taskImageDescription}.`,
          size: "1024x1024",
          quality: "standard",
          n: 1,
        });
        feedback = {
          type: "image",
          suggestions: dallEResponse.data[0].url,
          analysis: taskImageDescription,
        };
        break;

      default:
        return NextResponse.json(
          { error: "Invalid feedback type" },
          { status: 400 }
        );
    }

    return NextResponse.json({ feedback }, { status: 200 });
  } catch (error) {
    console.error("API å›é¥‹éŒ¯èª¤ï¼š", error);
    return NextResponse.json({ error: error.message }, { status: 500 });
  }
}
